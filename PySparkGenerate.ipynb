{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f834fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import datediff, current_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
    "import random\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230361b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/15 23:02:43 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.123 instead (on interface wlp0s20f3)\n",
      "23/09/15 23:02:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/15 23:02:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo SparkSession sinh dữ liệu\n",
    "spark = SparkSession.builder.appName(\"Generate and Save Parquet Data\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f15d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo schema cho DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), False),\n",
    "    StructField(\"Birthdate\", DateType(), False),\n",
    "    StructField(\"Address\", StringType(), False),\n",
    "    StructField(\"Gender\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0845e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo danh sách chứa 100 bản ghi ngẫu nhiên\n",
    "fake = Faker()\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    name = Faker().name()\n",
    "    birthdate = fake.date_of_birth(minimum_age=1, maximum_age=100)\n",
    "    address = fake.address()\n",
    "    gender = random.choice([\"Male\", \"Female\"])\n",
    "    record = (name, birthdate, address, gender)\n",
    "    data.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25862c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataFrame từ danh sách dữ liệu và schema\n",
    "df = spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0197d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán độ tuổi và thêm cột \"age\" vào DataFrame\n",
    "df = df.withColumn(\"age\", (datediff(current_date(), \"birthdate\") / 365).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9da3769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/09/15 14:31:29 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Lưu DataFrame thành tệp Parquet\n",
    "parquet_output_path = \"/home/hoanghainam/DE_internship/output.parquet\"\n",
    "df.write.mode(\"overwrite\").parquet(parquet_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d3dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc tệp Parquet và chuyển thành DataFrame\n",
    "parquet_file_path = \"/home/hoanghainam/DE_internship/output.parquet\"\n",
    "df = spark.read.parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e02415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+------+---+\n",
      "|             Name| Birthdate|             Address|Gender|age|\n",
      "+-----------------+----------+--------------------+------+---+\n",
      "|   Jeremy Perkins|2000-02-27|USCGC Morgan\\nFPO...|  Male| 23|\n",
      "|     Karen Parker|1948-06-27|165 Hatfield Fork...|Female| 75|\n",
      "|  Matthew Simmons|1983-08-01|8692 Billy Cliff\\...|Female| 40|\n",
      "|     Anne Bullock|1974-07-08|6351 Lopez Mills\\...|  Male| 49|\n",
      "|    Jeffrey Allen|1981-12-10|74474 Robinson Ca...|Female| 41|\n",
      "|    Micheal Green|1951-10-28|1463 Nicole Villa...|Female| 71|\n",
      "|       Ashley Gay|2017-10-18|9140 Hubbard Port...|  Male|  5|\n",
      "|     Angela Mckay|1958-05-25|76885 Jason Stree...|  Male| 65|\n",
      "|  Edward Benjamin|1941-01-28|6235 Jennifer Run...|  Male| 82|\n",
      "| Elizabeth Obrien|2003-03-28|51190 Becky Trail...|Female| 20|\n",
      "|   Eduardo Graham|1977-06-18|PSC 7096, Box 512...|  Male| 46|\n",
      "|      Brent Grant|1939-11-12|38731 Hernandez C...|Female| 83|\n",
      "|     Donna Acosta|1969-10-26|452 Lisa Mill\\nFl...|  Male| 53|\n",
      "|   Jennifer Hurst|2000-01-17|USNS Morrison\\nFP...|Female| 23|\n",
      "|    Sheryl Gibson|1939-04-26|443 Cynthia Highw...|  Male| 84|\n",
      "|    Robert Hanson|1940-04-24|9875 Rodriguez Ma...|Female| 83|\n",
      "|Cynthia Castaneda|1954-11-01|Unit 3606 Box 518...|Female| 68|\n",
      "|      Cory Morgan|2006-03-16|761 Williams Vist...|  Male| 17|\n",
      "|       Jason Webb|1979-04-03|705 David Orchard...|Female| 44|\n",
      "|   David Peterson|2016-01-08|7905 Cole Center ...|  Male|  7|\n",
      "+-----------------+----------+--------------------+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị dữ liệu trong DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df0ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dừng phiên làm việc Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416eafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
